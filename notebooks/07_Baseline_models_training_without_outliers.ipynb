{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline model training (without outliers)\n",
    "\n",
    "Basically the same as **07_Baseline_models_training_with_outliers.ipynb** notebook, but removing the outliers with the **OutlierImputer** class (**src/outlier_imputer.py**).\n",
    "\n",
    "I could have (and should have) done this comparison in the same notebook (with and without outliers imputing).<br>\n",
    "But, since the **DataPreprocessing** class is not yet super functional, I decided to split it in separate notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import standard libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.impute import SimpleImputer\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import custom scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.getcwd()+ \"/../\")\n",
    "from src.data_preprocessing import DataPreprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load all the features\n",
    "The datapreprocessing pipeline is doing quite some stuff, and in a non-efficient manner (I don't have much time for optimizing that :( )\n",
    "But it should be less than 2 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp = DataPreprocessing(df_path = \"../data/real_estate_ads_2022_10.csv\",\n",
    "                        train_indices_path=\"../data/train_indices.npy\", \n",
    "                        test_indices_path=\"../data/test_indices.npy\",\n",
    "                        remove_label_outliers_flag=True, # IMPORTANT FLAG\n",
    "                        get_params_from_params=True,\n",
    "                        get_tfidf_embeddings_flag=True,\n",
    "                        get_bert_embeddings_flag=True,\n",
    "                        get_textual_features_flag=True,\n",
    "                        transform_time_features_flag=True,\n",
    "                        transform_cyclic_features_flag=True)\n",
    "\n",
    "X_train, X_test = dp.get_train_test_split(dp.X)\n",
    "y_train, y_test = dp.get_train_test_split(dp.Y)\n",
    "\n",
    "imp_mean = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "X_train = pd.DataFrame(imp_mean.fit_transform(X_train), columns=X_train.columns)\n",
    "X_test = pd.DataFrame(imp_mean.transform(X_test), columns=X_test.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the metrics class\n",
    "That is convenient to compute multiple metrics:\n",
    "- **explained_variance_score**: Measures the proportion of the variance in the dependent variable that is predictable from the independent variable(s). A score of 1 indicates perfect prediction, while a score of 0 indicates that the model does not explain any of the variance.\n",
    "\n",
    "- **r2_score**: Also known as the coefficient of determination, it indicates the proportion of the variance in the dependent variable that is predictable from the independent variable(s). A value of 1 indicates a perfect fit, while a value of 0 indicates that the model does not explain any of the variance.\n",
    "\n",
    "- **mean_absolute_percentage_error (MAPE)**: Measures the average of the absolute percentage errors of predictions. It provides a percentage error which is easy to interpret but can be sensitive to very small actual values.\n",
    "\n",
    "- **median_absolute_error**: Computes the median of all absolute differences between the target and predicted values. This metric is robust to outliers and gives a better sense of the typical error when outliers are present.\n",
    "\n",
    "- **mean_absolute_error (MAE)**: Computes the mean of the absolute error (absolute difference between the target and predicted value). \n",
    "\n",
    "- **mean_squared_log_error (MSLE)**: Similar to MSE but takes the logarithm of the predictions and actual values. It is useful when you want to penalize underestimation more than overestimation and is less sensitive to large errors than MSE.\n",
    "\n",
    "- **custom metrics**: Compute the percentage of times that the error falls less than some threshold. This may correlate with customer satisfaction, if they are for example happy if there's less than a 5% rate, this would count the percentage of happy customers. Of course, this will need further study (for example, segmenting the score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'src'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mimportlib\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompute_metrics\u001b[39;00m\n\u001b[0;32m      3\u001b[0m importlib\u001b[38;5;241m.\u001b[39mreload(src\u001b[38;5;241m.\u001b[39mcompute_metrics) \u001b[38;5;66;03m# We do this for debugging purposes\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompute_metrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Metrics\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'src'"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import src.compute_metrics\n",
    "importlib.reload(src.compute_metrics) # We do this for debugging purposes\n",
    "\n",
    "from src.compute_metrics import Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a function for training\n",
    "We will use k-fold cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_get_metrics(model, X, y, backward_transform_label=True, backward_standardize_flag=False, verbose=False):\n",
    "\n",
    "    metrics = Metrics(dp=dp, backward_transform_flag=backward_transform_label, backward_standardize_flag=backward_standardize_flag)\n",
    "\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    for train_index, test_index in kf.split(X, y):\n",
    "        X_train, X_val = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_val = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_val)\n",
    "\n",
    "        if verbose: \n",
    "            print(f\"y_pred: {y_pred[:5]}\")\n",
    "            print(f\"y_val: {y_val[:5]}\")\n",
    "\n",
    "\n",
    "        computed_metrics = metrics.get_single_train_val_metrics(model, X_train, y_train, X_val, y_val)\n",
    "        metrics.append(computed_metrics)\n",
    "\n",
    "    average_metrics = metrics.get_average()\n",
    "    std_metrics = metrics.get_std()\n",
    "    # Add _std to the keys to differentiate them from the average metrics:\n",
    "    std_metrics = {f\"{key}_std\" : value for key, value in std_metrics.items()} \n",
    "\n",
    "    return {**average_metrics, **std_metrics}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define convenience functions for prettier display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_metrics(metrics_dict, only_validation=True, format_mean_std_together=True):\n",
    "\n",
    "    if only_validation:\n",
    "        metrics_dict = {key: value for key, value in metrics_dict.items() if \"test_\" in key}\n",
    "\n",
    "    if format_mean_std_together:\n",
    "        metrics_dict = {key: f\"{value:.2f} ± {metrics_dict[key+'_std']:.2f}\" for key, value in metrics_dict.items() if \"std\" not in key}\n",
    "\n",
    "    return metrics_dict\n",
    "\n",
    "def highlight_max(s):\n",
    "    is_max = s == s.replace(\"nan ± nan\", \"0\").max()\n",
    "    return ['font-weight: bold' if v else '' for v in is_max]\n",
    "\n",
    "def format_results_df(results, column_names=None):\n",
    "    results_df = pd.DataFrame(results).T\n",
    "\n",
    "    if column_names is not None:\n",
    "        results_df.columns = column_names\n",
    "    \n",
    "    return results_df.style.apply(highlight_max, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import and define baseline models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use simple linear models\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# Support vector machines\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "# K neighbors classifiers\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Decision trees\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Random forests\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear regression\n",
      "y_pred: [[ 0.55614892]\n",
      " [-0.55747703]\n",
      " [ 1.17770557]\n",
      " [-0.55847119]\n",
      " [ 0.5103213 ]]\n",
      "y_val:        price_per_m\n",
      "18563     0.248746\n",
      "49795    -0.828817\n",
      "11597     1.017808\n",
      "16528    -0.577675\n",
      "62540    -0.107894\n",
      "y_pred: [[ 0.16206179]\n",
      " [-0.41284075]\n",
      " [-0.13639937]\n",
      " [-0.68935287]\n",
      " [ 0.43581587]]\n",
      "y_val:        price_per_m\n",
      "34086     0.173084\n",
      "41636    -0.444718\n",
      "20321     0.596778\n",
      "66567    -0.722584\n",
      "35278     1.328041\n",
      "y_pred: [[ 0.02338851]\n",
      " [ 0.8259965 ]\n",
      " [-0.8684811 ]\n",
      " [ 0.25633631]\n",
      " [ 0.51677796]]\n",
      "y_val:        price_per_m\n",
      "23851    -0.133053\n",
      "71706     0.220067\n",
      "7683     -1.013503\n",
      "66762     0.112159\n",
      "71258    -0.330539\n",
      "y_pred: [[ 0.09859211]\n",
      " [-0.02956057]\n",
      " [ 0.28437683]\n",
      " [-0.09705792]\n",
      " [ 0.18122024]]\n",
      "y_val:        price_per_m\n",
      "2898      0.132444\n",
      "26381     0.452741\n",
      "71395     0.287999\n",
      "51329    -0.112959\n",
      "40072     0.073805\n",
      "y_pred: [[-0.01115963]\n",
      " [ 0.48467624]\n",
      " [-0.56420116]\n",
      " [-0.41709127]\n",
      " [ 0.24578029]]\n",
      "y_val:        price_per_m\n",
      "6943     -1.042554\n",
      "63401     0.104377\n",
      "67204    -0.839440\n",
      "11930    -0.661646\n",
      "10049     0.783902\n",
      "Lasso\n",
      "y_pred: [ 0.38106939 -0.11402549  0.16742728  0.1236603   0.09817434]\n",
      "y_val:        price_per_m\n",
      "18563     0.248746\n",
      "49795    -0.828817\n",
      "11597     1.017808\n",
      "16528    -0.577675\n",
      "62540    -0.107894\n",
      "y_pred: [ 0.02018674 -0.01793045 -0.28142314 -0.25367763  0.02981406]\n",
      "y_val:        price_per_m\n",
      "34086     0.173084\n",
      "41636    -0.444718\n",
      "20321     0.596778\n",
      "66567    -0.722584\n",
      "35278     1.328041\n",
      "y_pred: [ 0.05090692  0.12837125 -0.14308007 -0.04037279  0.144982  ]\n",
      "y_val:        price_per_m\n",
      "23851    -0.133053\n",
      "71706     0.220067\n",
      "7683     -1.013503\n",
      "66762     0.112159\n",
      "71258    -0.330539\n",
      "y_pred: [-0.1655913   0.22958153  0.17816854 -0.2892539   0.04722283]\n",
      "y_val:        price_per_m\n",
      "2898      0.132444\n",
      "26381     0.452741\n",
      "71395     0.287999\n",
      "51329    -0.112959\n",
      "40072     0.073805\n",
      "y_pred: [-0.4361781   0.05089688 -0.22303197 -0.11787837  0.02553761]\n",
      "y_val:        price_per_m\n",
      "6943     -1.042554\n",
      "63401     0.104377\n",
      "67204    -0.839440\n",
      "11930    -0.661646\n",
      "10049     0.783902\n"
     ]
    }
   ],
   "source": [
    "linear_models = {\n",
    "    \"Linear regression\" : {\n",
    "        \"model\": LinearRegression(),\n",
    "        },\n",
    "    \"Lasso\" : {\n",
    "        \"model\": Lasso(),\n",
    "        },\n",
    "    }\n",
    "\n",
    "results_list = []\n",
    "\n",
    "for model_name in linear_models:\n",
    "    print(model_name)\n",
    "    model = linear_models[model_name][\"model\"]\n",
    "\n",
    "    results = train_and_get_metrics(model, X_train, y_train, verbose=True)\n",
    "    results_list.append(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_45752_row0_col0, #T_45752_row1_col0, #T_45752_row2_col1, #T_45752_row3_col0, #T_45752_row4_col1, #T_45752_row5_col1, #T_45752_row6_col0, #T_45752_row7_col0, #T_45752_row8_col0, #T_45752_row9_col0 {\n",
       "  font-weight: bold;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_45752\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_45752_level0_col0\" class=\"col_heading level0 col0\" >Linear regression</th>\n",
       "      <th id=\"T_45752_level0_col1\" class=\"col_heading level0 col1\" >Lasso</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_45752_level0_row0\" class=\"row_heading level0 row0\" >test_explained_variance</th>\n",
       "      <td id=\"T_45752_row0_col0\" class=\"data row0 col0\" >0.46 ± 0.01</td>\n",
       "      <td id=\"T_45752_row0_col1\" class=\"data row0 col1\" >0.09 ± 0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_45752_level0_row1\" class=\"row_heading level0 row1\" >test_r2</th>\n",
       "      <td id=\"T_45752_row1_col0\" class=\"data row1 col0\" >0.45 ± 0.01</td>\n",
       "      <td id=\"T_45752_row1_col1\" class=\"data row1 col1\" >0.08 ± 0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_45752_level0_row2\" class=\"row_heading level0 row2\" >test_mape</th>\n",
       "      <td id=\"T_45752_row2_col0\" class=\"data row2 col0\" >0.14 ± 0.00</td>\n",
       "      <td id=\"T_45752_row2_col1\" class=\"data row2 col1\" >0.19 ± 0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_45752_level0_row3\" class=\"row_heading level0 row3\" >test_median_absolute_error</th>\n",
       "      <td id=\"T_45752_row3_col0\" class=\"data row3 col0\" >756.75 ± 7.82</td>\n",
       "      <td id=\"T_45752_row3_col1\" class=\"data row3 col1\" >1096.48 ± 7.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_45752_level0_row4\" class=\"row_heading level0 row4\" >test_mean_squared_error</th>\n",
       "      <td id=\"T_45752_row4_col0\" class=\"data row4 col0\" >3266531.51 ± 103833.13</td>\n",
       "      <td id=\"T_45752_row4_col1\" class=\"data row4 col1\" >5500837.63 ± 142315.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_45752_level0_row5\" class=\"row_heading level0 row5\" >test_mean_squared_log_error</th>\n",
       "      <td id=\"T_45752_row5_col0\" class=\"data row5 col0\" >0.04 ± 0.00</td>\n",
       "      <td id=\"T_45752_row5_col1\" class=\"data row5 col1\" >0.06 ± 0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_45752_level0_row6\" class=\"row_heading level0 row6\" >test_custom_1</th>\n",
       "      <td id=\"T_45752_row6_col0\" class=\"data row6 col0\" >5.56 ± 0.27</td>\n",
       "      <td id=\"T_45752_row6_col1\" class=\"data row6 col1\" >4.05 ± 0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_45752_level0_row7\" class=\"row_heading level0 row7\" >test_custom_5</th>\n",
       "      <td id=\"T_45752_row7_col0\" class=\"data row7 col0\" >27.27 ± 0.45</td>\n",
       "      <td id=\"T_45752_row7_col1\" class=\"data row7 col1\" >18.83 ± 0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_45752_level0_row8\" class=\"row_heading level0 row8\" >test_custom_10</th>\n",
       "      <td id=\"T_45752_row8_col0\" class=\"data row8 col0\" >50.83 ± 0.55</td>\n",
       "      <td id=\"T_45752_row8_col1\" class=\"data row8 col1\" >36.71 ± 0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_45752_level0_row9\" class=\"row_heading level0 row9\" >test_custom_20</th>\n",
       "      <td id=\"T_45752_row9_col0\" class=\"data row9 col0\" >80.12 ± 0.32</td>\n",
       "      <td id=\"T_45752_row9_col1\" class=\"data row9 col1\" >65.22 ± 0.34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x19823d26fc0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_results = [filter_metrics(results) for results in results_list]\n",
    "format_results_df(filtered_results, column_names=linear_models.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The metrics now are a bit worse.\n",
    "\n",
    "Since removing outliers can remove some information, we decide not to remove them."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "olx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
